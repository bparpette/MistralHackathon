#!/usr/bin/env python3
"""
Chat Simple avec Mistral - Int√©gration compl√®te des fonctionnalit√©s
Utilise toutes les fonctions d√©velopp√©es pour un chat intelligent
"""

import os
import json
import hashlib
from datetime import datetime
from typing import Dict, List, Optional
import sys

# Ajouter le r√©pertoire parent pour importer main
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importer toutes les fonctions du main.py
from main import (
    # Fonctions de base
    verify_user_token, extract_token_from_headers,
    ensure_mistral_import, generate_embedding, get_storage,
    
    # Fonctions de conversation
    chat_with_mistral, end_chat_and_summarize,
    search_past_conversations, get_full_transcript,
    
    # Fonctions de m√©moire
    add_memory, search_memories, list_memories,
    
    # Configuration
    MISTRAL_ENABLED, MISTRAL_API_KEY, IS_LAMBDA
)

class SimpleChat:
    """Chat simple avec toutes les fonctionnalit√©s int√©gr√©es"""
    
    def __init__(self):
        self.conversation_id = None
        self.user_info = None
        self.storage = None
        self.mistral = None
        
        # Initialiser les services
        self._initialize_services()
    
    def _initialize_services(self):
        """Initialiser tous les services n√©cessaires"""
        print("üîß Initialisation des services...")
        
        # Initialiser Mistral
        ensure_mistral_import()
        if MISTRAL_ENABLED and MISTRAL_API_KEY:
            from mistralai import Mistral
            self.mistral = Mistral(api_key=MISTRAL_API_KEY)
            print("‚úÖ Mistral initialis√©")
        else:
            print("‚ùå Mistral non configur√©")
        
        # Initialiser le stockage
        self.storage = get_storage()
        if self.storage:
            print("‚úÖ Stockage vectoriel initialis√©")
        else:
            print("‚ö†Ô∏è Stockage vectoriel non disponible")
        
        # Mode test par d√©faut
        self.user_info = {
            "user_id": "user_unified_test",  # ID unifi√© pour toutes les conversations
            "team_id": "test-team-123",
            "user_name": "Utilisateur Test"
        }
        print("‚úÖ Mode test activ√©")
    
    def start_conversation(self, user_name: str = "Utilisateur"):
        """D√©marrer une nouvelle conversation"""
        self.conversation_id = hashlib.md5(f"{user_name}-{datetime.now().isoformat()}".encode()).hexdigest()
        self.user_info["user_name"] = user_name
        
        print(f"\nüéØ Nouvelle conversation d√©marr√©e")
        print(f"üìù ID: {self.conversation_id}")
        print(f"üë§ Utilisateur: {user_name}")
        print(f"üß† Stockage: {'‚úÖ' if self.storage else '‚ùå'}")
        print(f"ü§ñ Mistral: {'‚úÖ' if self.mistral else '‚ùå'}")
        print("\n" + "="*50)
        print("üí¨ Tapez votre message (ou 'quit' pour quitter, 'help' pour l'aide)")
        print("="*50)
    
    def _search_relevant_conversations(self, query: str) -> List[Dict]:
        """Rechercher des conversations pertinentes"""
        if not self.storage:
            return []
        
        try:
            # Rechercher dans les conversations pass√©es
            result = search_past_conversations(query, limit=3)
            data = json.loads(result)
            
            if data.get("status") == "success":
                return data.get("results", [])
            else:
                print(f"‚ö†Ô∏è Erreur recherche conversations: {data.get('message')}")
                return []
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche: {e}")
            return []
    
    def _search_memories(self, query: str) -> List[Dict]:
        """Rechercher dans les m√©moires"""
        if not self.storage:
            return []
        
        try:
            result = search_memories(query, limit=5)
            data = json.loads(result)
            
            if data.get("status") == "success":
                return data.get("results", [])
            else:
                print(f"‚ö†Ô∏è Erreur recherche m√©moires: {data.get('message')}")
                return []
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche de m√©moires: {e}")
            return []
    
    def _get_full_conversation(self, chat_id: str) -> Optional[str]:
        """R√©cup√©rer une conversation compl√®te"""
        try:
            result = get_full_transcript(chat_id)
            data = json.loads(result)
            
            if data.get("status") == "success":
                return data.get("transcript")
            else:
                print(f"‚ö†Ô∏è Erreur r√©cup√©ration conversation: {data.get('message')}")
                return None
        except Exception as e:
            print(f"‚ùå Erreur lors de la r√©cup√©ration: {e}")
            return None
    
    def _add_memory(self, content: str, tags: str = "", category: str = "general"):
        """Ajouter une m√©moire"""
        try:
            result = add_memory(content, tags, category)
            data = json.loads(result)
            
            if data.get("status") == "success":
                print(f"üíæ M√©moire ajout√©e: {data.get('message')}")
            else:
                print(f"‚ö†Ô∏è Erreur ajout m√©moire: {data.get('message')}")
        except Exception as e:
            print(f"‚ùå Erreur lors de l'ajout de m√©moire: {e}")
    
    def _generate_response_with_context(self, user_message: str) -> str:
        """G√©n√©rer une r√©ponse avec contexte des conversations pass√©es"""
        if not self.mistral:
            return "‚ùå Mistral n'est pas configur√©. Veuillez configurer MISTRAL_API_KEY."
        
        # 1. Rechercher des conversations pertinentes
        print("üîç Recherche de conversations pertinentes...")
        relevant_conversations = self._search_relevant_conversations(user_message)
        
        # 2. Rechercher des m√©moires pertinentes
        print("üß† Recherche dans les m√©moires...")
        relevant_memories = self._search_memories(user_message)
        
        # 3. Construire le contexte
        context = ""
        
        if relevant_conversations:
            context += "\nüìö CONVERSATIONS PERTINENTES TROUV√âES:\n"
            for i, conv in enumerate(relevant_conversations, 1):
                context += f"\n--- Conversation {i} ---\n"
                context += f"R√©sum√©: {conv.get('summary', 'N/A')}\n"
                context += f"Score: {conv.get('score', 0):.3f}\n"
                context += f"Date: {conv.get('timestamp', 'N/A')}\n"
        
        if relevant_memories:
            context += "\nüíæ M√âMOIRES PERTINENTES:\n"
            for i, mem in enumerate(relevant_memories, 1):
                context += f"\n--- M√©moire {i} ---\n"
                context += f"Contenu: {mem.get('content', 'N/A')}\n"
                context += f"Cat√©gorie: {mem.get('category', 'N/A')}\n"
                context += f"Score: {mem.get('similarity_score', 0):.3f}\n"
        
        # 4. Si des conversations sont tr√®s pertinentes, r√©cup√©rer les d√©tails
        detailed_context = ""
        if relevant_conversations:
            # Prendre la conversation la plus pertinente
            best_conv = max(relevant_conversations, key=lambda x: x.get('score', 0))
            if best_conv.get('score', 0) > 0.7:  # Seuil de pertinence
                print(f"üìñ R√©cup√©ration des d√©tails de la conversation {best_conv.get('chat_id')}...")
                full_transcript = self._get_full_conversation(best_conv.get('chat_id'))
                if full_transcript:
                    detailed_context = f"\nüìñ D√âTAILS DE LA CONVERSATION LA PLUS PERTINENTE:\n{full_transcript}\n"
        
        # 5. Construire le prompt final
        system_prompt = f"""Tu es un assistant IA expert avec acc√®s √† une m√©moire collective et aux conversations pass√©es.

CONTEXTE DISPONIBLE:
{context}
{detailed_context}

INSTRUCTIONS:
- Utilise le contexte fourni pour r√©pondre de mani√®re pertinente
- Si tu trouves des informations utiles dans les conversations/m√©moires, cite-les
- Si l'utilisateur pose une question sp√©cifique, cherche dans le contexte
- Si tu ajoutes de nouvelles informations importantes, mentionne-le
- Sois pr√©cis et utile en utilisant toutes les informations disponibles

R√©ponds de mani√®re naturelle et utile en fran√ßais."""

        try:
            # Appel √† Mistral avec le contexte
            response = self.mistral.chat.complete(
                model="mistral-large-latest",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"‚ùå Erreur lors de la g√©n√©ration de r√©ponse: {e}"
    
    def _summarize_conversation(self) -> str:
        """R√©sumer la conversation actuelle"""
        if not self.conversation_id:
            return "Aucune conversation en cours"
        
        try:
            result = end_chat_and_summarize(self.conversation_id)
            data = json.loads(result)
            
            if data.get("status") == "success":
                summary = data.get("summary", "R√©sum√© non disponible")
                print(f"\nüìù R√âSUM√â DE LA CONVERSATION:")
                print(f"{summary}")
                print(f"\nüíæ Conversation sauvegard√©e avec l'ID: {self.conversation_id}")
                return summary
            else:
                print(f"‚ö†Ô∏è Erreur lors du r√©sum√©: {data.get('message')}")
                return "Erreur lors du r√©sum√©"
        except Exception as e:
            print(f"‚ùå Erreur lors du r√©sum√©: {e}")
            return "Erreur lors du r√©sum√©"
    
    def chat_loop(self):
        """Boucle principale du chat"""
        if not self.mistral:
            print("‚ùå Impossible de d√©marrer le chat: Mistral non configur√©")
            return
        
        print("üöÄ D√©marrage du chat simple...")
        self.start_conversation()
        
        while True:
            try:
                # Lire l'entr√©e utilisateur
                user_input = input("\nüë§ Vous: ").strip()
                
                # Commandes sp√©ciales
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("\nüëã Fin de la conversation...")
                    self._summarize_conversation()
                    break
                
                elif user_input.lower() == 'help':
                    self._show_help()
                    continue
                
                elif user_input.lower() == 'summary':
                    self._summarize_conversation()
                    continue
                
                elif user_input.lower() == 'memories':
                    self._show_memories()
                    continue
                
                elif user_input.lower() == 'search':
                    self._interactive_search()
                    continue
                
                elif not user_input:
                    continue
                
                # Traiter le message
                print("\nü§ñ Assistant: ", end="", flush=True)
                response = self._generate_response_with_context(user_input)
                print(response)
                
                # Ajouter automatiquement des informations importantes √† la m√©moire
                if any(keyword in user_input.lower() for keyword in ['important', 'souviens-toi', 'note', 'd√©cision', 'solution']):
                    print("üíæ Ajout automatique √† la m√©moire...")
                    self._add_memory(user_input, category="important")
                
            except KeyboardInterrupt:
                print("\n\nüëã Interruption d√©tect√©e...")
                self._summarize_conversation()
                break
            except Exception as e:
                print(f"\n‚ùå Erreur: {e}")
                continue
    
    def _show_help(self):
        """Afficher l'aide"""
        print("\nüìö COMMANDES DISPONIBLES:")
        print("  help     - Afficher cette aide")
        print("  summary  - R√©sumer la conversation actuelle")
        print("  memories - Afficher les m√©moires r√©centes")
        print("  search   - Recherche interactive")
        print("  quit     - Quitter le chat")
        print("\nüí° Le chat utilise automatiquement:")
        print("  - Recherche dans les conversations pass√©es")
        print("  - Recherche dans les m√©moires")
        print("  - R√©sum√© automatique √† la fin")
        print("  - Sauvegarde des conversations")
    
    def _show_memories(self):
        """Afficher les m√©moires"""
        try:
            result = list_memories()
            data = json.loads(result)
            
            if data.get("status") == "success":
                memories = data.get("memories", [])
                print(f"\nüíæ M√âMOIRES ({len(memories)} trouv√©es):")
                for i, mem in enumerate(memories[:10], 1):  # Limiter √† 10
                    print(f"\n{i}. {mem.get('content', 'N/A')[:100]}...")
                    print(f"   Cat√©gorie: {mem.get('category', 'N/A')}")
                    print(f"   Date: {mem.get('timestamp', 'N/A')}")
            else:
                print(f"‚ö†Ô∏è Erreur: {data.get('message')}")
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
    
    def _interactive_search(self):
        """Recherche interactive"""
        query = input("üîç Terme de recherche: ").strip()
        if not query:
            return
        
        print(f"\nüîç Recherche de: '{query}'")
        
        # Rechercher dans les conversations
        conversations = self._search_relevant_conversations(query)
        if conversations:
            print(f"\nüìö CONVERSATIONS TROUV√âES ({len(conversations)}):")
            for i, conv in enumerate(conversations, 1):
                print(f"\n{i}. Score: {conv.get('score', 0):.3f}")
                print(f"   R√©sum√©: {conv.get('summary', 'N/A')[:200]}...")
                print(f"   Date: {conv.get('timestamp', 'N/A')}")
        
        # Rechercher dans les m√©moires
        memories = self._search_memories(query)
        if memories:
            print(f"\nüíæ M√âMOIRES TROUV√âES ({len(memories)}):")
            for i, mem in enumerate(memories, 1):
                print(f"\n{i}. Score: {mem.get('similarity_score', 0):.3f}")
                print(f"   Contenu: {mem.get('content', 'N/A')[:200]}...")
                print(f"   Cat√©gorie: {mem.get('category', 'N/A')}")

def main():
    """Fonction principale"""
    print("üß† Chat Simple avec Mistral - Version Compl√®te")
    print("=" * 50)
    
    # V√©rifier la configuration
    if not MISTRAL_ENABLED or not MISTRAL_API_KEY:
        print("‚ö†Ô∏è ATTENTION: Mistral n'est pas configur√©!")
        print("   Configurez MISTRAL_API_KEY dans votre fichier .env")
        print("   Le chat fonctionnera en mode limit√©")
        print()
    
    # Cr√©er et d√©marrer le chat
    chat = SimpleChat()
    chat.chat_loop()

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
Chat Avanc√© avec Mistral - R√©sumation automatique √† chaque message
Version optimis√©e avec r√©sumation continue et recherche intelligente
"""

import os
import json
import hashlib
from datetime import datetime
from typing import Dict, List, Optional
import sys

# Ajouter le r√©pertoire parent pour importer main
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importer toutes les fonctions du main.py
from main import (
    # Fonctions de base
    verify_user_token, extract_token_from_headers,
    ensure_mistral_import, generate_embedding, get_storage,
    
    # Fonctions de conversation
    chat_with_mistral, end_chat_and_summarize,
    search_past_conversations, get_full_transcript,
    
    # Fonctions de m√©moire
    add_memory, search_memories, list_memories,
    
    # Configuration
    MISTRAL_ENABLED, MISTRAL_API_KEY, IS_LAMBDA
)

class AdvancedChat:
    """Chat avanc√© avec r√©sumation automatique et recherche intelligente"""
    
    def __init__(self):
        self.conversation_id = None
        self.user_info = None
        self.storage = None
        self.mistral = None
        self.conversation_history = []
        self.summary_threshold = 3  # R√©sumer tous les 3 messages
        
        # Initialiser les services
        self._initialize_services()
    
    def _initialize_services(self):
        """Initialiser tous les services n√©cessaires"""
        print("üîß Initialisation des services avanc√©s...")
        
        # Initialiser Mistral
        ensure_mistral_import()
        if MISTRAL_ENABLED and MISTRAL_API_KEY:
            from mistralai import Mistral
            self.mistral = Mistral(api_key=MISTRAL_API_KEY)
            print("‚úÖ Mistral initialis√©")
        else:
            print("‚ùå Mistral non configur√©")
        
        # Initialiser le stockage
        self.storage = get_storage()
        if self.storage:
            print("‚úÖ Stockage vectoriel initialis√©")
        else:
            print("‚ö†Ô∏è Stockage vectoriel non disponible")
        
        # Mode test par d√©faut
        self.user_info = {
            "user_id": "user_unified_test",  # ID unifi√© pour toutes les conversations
            "team_id": "test-team-123",
            "user_name": "Utilisateur Test"
        }
        print("‚úÖ Mode test activ√©")
    
    def start_conversation(self, user_name: str = "Utilisateur"):
        """D√©marrer une nouvelle conversation"""
        self.conversation_id = hashlib.md5(f"{user_name}-{datetime.now().isoformat()}".encode()).hexdigest()
        self.user_info["user_name"] = user_name
        self.conversation_history = []
        
        print(f"\nüéØ Nouvelle conversation avanc√©e d√©marr√©e")
        print(f"üìù ID: {self.conversation_id}")
        print(f"üë§ Utilisateur: {user_name}")
        print(f"üß† Stockage: {'‚úÖ' if self.storage else '‚ùå'}")
        print(f"ü§ñ Mistral: {'‚úÖ' if self.mistral else '‚ùå'}")
        print(f"üìä R√©sumation: Tous les {self.summary_threshold} messages")
        print("\n" + "="*60)
        print("üí¨ Tapez votre message (ou 'quit' pour quitter, 'help' pour l'aide)")
        print("="*60)
    
    def _auto_summarize(self) -> str:
        """R√©sumer automatiquement la conversation actuelle"""
        if len(self.conversation_history) < 2:
            return ""
        
        if not self.mistral:
            return ""
        
        try:
            from main import generate_continuous_summary
            summary = generate_continuous_summary(
                self.conversation_history,
                self.conversation_id,
                self.user_info["team_id"]
            )
            return summary
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur r√©sumation automatique: {e}")
            return ""
    
    def _search_relevant_conversations(self, query: str) -> List[Dict]:
        """Rechercher des conversations pertinentes avec scoring intelligent"""
        if not self.storage:
            return []
        
        try:
            # Rechercher dans les conversations pass√©es
            result = search_past_conversations(query, limit=5)
            data = json.loads(result)
            
            if data.get("status") == "success":
                conversations = data.get("results", [])
                # Filtrer les conversations tr√®s pertinentes (score > 0.5)
                relevant = [conv for conv in conversations if conv.get('score', 0) > 0.5]
                return relevant
            else:
                print(f"‚ö†Ô∏è Erreur recherche conversations: {data.get('message')}")
                return []
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche: {e}")
            return []
    
    def _search_memories(self, query: str) -> List[Dict]:
        """Rechercher dans les m√©moires avec scoring intelligent"""
        if not self.storage:
            return []
        
        try:
            result = search_memories(query, limit=5)
            data = json.loads(result)
            
            if data.get("status") == "success":
                memories = data.get("results", [])
                # Filtrer les m√©moires tr√®s pertinentes (score > 0.3)
                relevant = [mem for mem in memories if mem.get('similarity_score', 0) > 0.3]
                return relevant
            else:
                print(f"‚ö†Ô∏è Erreur recherche m√©moires: {data.get('message')}")
                return []
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche de m√©moires: {e}")
            return []
    
    def _get_full_conversation(self, chat_id: str) -> Optional[str]:
        """R√©cup√©rer une conversation compl√®te"""
        try:
            result = get_full_transcript(chat_id)
            data = json.loads(result)
            
            if data.get("status") == "success":
                return data.get("transcript")
            else:
                print(f"‚ö†Ô∏è Erreur r√©cup√©ration conversation: {data.get('message')}")
                return None
        except Exception as e:
            print(f"‚ùå Erreur lors de la r√©cup√©ration: {e}")
            return None
    
    def _add_memory(self, content: str, tags: str = "", category: str = "general"):
        """Ajouter une m√©moire"""
        try:
            result = add_memory(content, tags, category)
            data = json.loads(result)
            
            if data.get("status") == "success":
                print(f"üíæ M√©moire ajout√©e: {data.get('message')}")
            else:
                print(f"‚ö†Ô∏è Erreur ajout m√©moire: {data.get('message')}")
        except Exception as e:
            print(f"‚ùå Erreur lors de l'ajout de m√©moire: {e}")
    
    def _generate_intelligent_response(self, user_message: str) -> str:
        """G√©n√©rer une r√©ponse intelligente avec contexte complet"""
        if not self.mistral:
            return "‚ùå Mistral n'est pas configur√©. Veuillez configurer MISTRAL_API_KEY."
        
        print("üîç Recherche de contexte pertinent...")
        
        # 1. Rechercher des conversations pertinentes
        relevant_conversations = self._search_relevant_conversations(user_message)
        
        # 2. Rechercher des m√©moires pertinentes
        relevant_memories = self._search_memories(user_message)
        
        # 3. Construire le contexte intelligent
        context_parts = []
        
        if relevant_conversations:
            context_parts.append("üìö CONVERSATIONS PERTINENTES:")
            for i, conv in enumerate(relevant_conversations, 1):
                context_parts.append(f"\n--- Conversation {i} (Score: {conv.get('score', 0):.3f}) ---")
                context_parts.append(f"R√©sum√©: {conv.get('summary', 'N/A')}")
                context_parts.append(f"Date: {conv.get('timestamp', 'N/A')}")
        
        if relevant_memories:
            context_parts.append("\nüíæ M√âMOIRES PERTINENTES:")
            for i, mem in enumerate(relevant_memories, 1):
                context_parts.append(f"\n--- M√©moire {i} (Score: {mem.get('similarity_score', 0):.3f}) ---")
                context_parts.append(f"Contenu: {mem.get('content', 'N/A')}")
                context_parts.append(f"Cat√©gorie: {mem.get('category', 'N/A')}")
        
        # 4. R√©cup√©rer les d√©tails de la conversation la plus pertinente
        detailed_context = ""
        if relevant_conversations:
            best_conv = max(relevant_conversations, key=lambda x: x.get('score', 0))
            if best_conv.get('score', 0) > 0.7:
                print(f"üìñ R√©cup√©ration des d√©tails de la conversation {best_conv.get('chat_id')}...")
                full_transcript = self._get_full_conversation(best_conv.get('chat_id'))
                if full_transcript:
                    detailed_context = f"\nüìñ D√âTAILS DE LA CONVERSATION LA PLUS PERTINENTE:\n{full_transcript}\n"
        
        # 5. Construire le prompt final avec contexte
        context = "\n".join(context_parts) if context_parts else "Aucun contexte pertinent trouv√©."
        
        system_prompt = f"""Tu es un assistant IA expert avec acc√®s √† une m√©moire collective et aux conversations pass√©es.

CONTEXTE DISPONIBLE:
{context}
{detailed_context}

HISTORIQUE DE LA CONVERSATION ACTUELLE:
{self._get_conversation_summary()}

INSTRUCTIONS:
- Utilise TOUT le contexte fourni pour r√©pondre de mani√®re pertinente et pr√©cise
- Si tu trouves des informations utiles dans les conversations/m√©moires, cite-les clairement
- Si l'utilisateur pose une question sp√©cifique, cherche dans le contexte et r√©ponds avec des d√©tails
- Si tu ajoutes de nouvelles informations importantes, mentionne-le
- Sois naturel, utile et pr√©cis en utilisant toutes les informations disponibles
- R√©ponds en fran√ßais de mani√®re conversationnelle

R√©ponds de mani√®re naturelle et utile."""

        try:
            # Appel √† Mistral avec le contexte complet
            response = self.mistral.chat.complete(
                model="mistral-large-latest",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"‚ùå Erreur lors de la g√©n√©ration de r√©ponse: {e}"
    
    def _get_conversation_summary(self) -> str:
        """Obtenir un r√©sum√© de la conversation actuelle"""
        if len(self.conversation_history) <= 1:
            return "Conversation r√©cemment d√©marr√©e."
        
        # Prendre les 3 derniers √©changes
        recent_messages = self.conversation_history[-6:]  # 3 √©changes = 6 messages
        return "\n".join([f"{msg['role']}: {msg['content']}" for msg in recent_messages])
    
    def _finalize_conversation(self) -> str:
        """Finaliser et sauvegarder la conversation"""
        if not self.conversation_id or not self.conversation_history:
            return "Aucune conversation √† finaliser"
        
        try:
            # Utiliser la fonction existante pour finaliser
            result = end_chat_and_summarize(self.conversation_id)
            data = json.loads(result)
            
            if data.get("status") == "success":
                summary = data.get("summary", "R√©sum√© non disponible")
                print(f"\nüìù R√âSUM√â FINAL DE LA CONVERSATION:")
                print(f"{summary}")
                print(f"\nüíæ Conversation sauvegard√©e avec l'ID: {self.conversation_id}")
                return summary
            else:
                print(f"‚ö†Ô∏è Erreur lors de la finalisation: {data.get('message')}")
                return "Erreur lors de la finalisation"
        except Exception as e:
            print(f"‚ùå Erreur lors de la finalisation: {e}")
            return "Erreur lors de la finalisation"
    
    def chat_loop(self):
        """Boucle principale du chat avanc√©"""
        if not self.mistral:
            print("‚ùå Impossible de d√©marrer le chat: Mistral non configur√©")
            return
        
        print("üöÄ D√©marrage du chat avanc√©...")
        self.start_conversation()
        
        while True:
            try:
                # Lire l'entr√©e utilisateur
                user_input = input("\nüë§ Vous: ").strip()
                
                # Commandes sp√©ciales
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("\nüëã Finalisation de la conversation...")
                    self._finalize_conversation()
                    break
                
                elif user_input.lower() == 'help':
                    self._show_help()
                    continue
                
                elif user_input.lower() == 'summary':
                    auto_summary = self._auto_summarize()
                    if auto_summary:
                        print(f"\nüìù R√âSUM√â AUTOMATIQUE:\n{auto_summary}")
                    else:
                        print("‚ö†Ô∏è Impossible de g√©n√©rer un r√©sum√© automatique")
                    continue
                
                elif user_input.lower() == 'memories':
                    self._show_memories()
                    continue
                
                elif user_input.lower() == 'search':
                    self._interactive_search()
                    continue
                
                elif not user_input:
                    continue
                
                # Ajouter le message utilisateur √† l'historique
                self.conversation_history.append({"role": "user", "content": user_input})
                
                # G√©n√©rer la r√©ponse intelligente
                print("\nü§ñ Assistant: ", end="", flush=True)
                response = self._generate_intelligent_response(user_input)
                print(response)
                
                # Ajouter la r√©ponse √† l'historique
                self.conversation_history.append({"role": "assistant", "content": response})
                
                # R√©sumation automatique si n√©cessaire
                if len(self.conversation_history) % (self.summary_threshold * 2) == 0:  # *2 car user + assistant
                    print("\nüîÑ R√©sumation automatique en cours...")
                    auto_summary = self._auto_summarize()
                    if auto_summary:
                        print(f"üìù R√©sum√©: {auto_summary}")
                
                # Ajouter automatiquement des informations importantes √† la m√©moire
                if any(keyword in user_input.lower() for keyword in ['important', 'souviens-toi', 'note', 'd√©cision', 'solution', 'bug', 'probl√®me']):
                    print("üíæ Ajout automatique √† la m√©moire...")
                    self._add_memory(user_input, category="important")
                
            except KeyboardInterrupt:
                print("\n\nüëã Interruption d√©tect√©e...")
                self._finalize_conversation()
                break
            except Exception as e:
                print(f"\n‚ùå Erreur: {e}")
                continue
    
    def _show_help(self):
        """Afficher l'aide"""
        print("\nüìö COMMANDES DISPONIBLES:")
        print("  help     - Afficher cette aide")
        print("  summary  - R√©sum√© automatique de la conversation actuelle")
        print("  memories - Afficher les m√©moires r√©centes")
        print("  search   - Recherche interactive")
        print("  quit     - Quitter le chat")
        print("\nü§ñ FONCTIONNALIT√âS AUTOMATIQUES:")
        print("  - R√©sumation automatique tous les 3 √©changes")
        print("  - Recherche intelligente dans les conversations pass√©es")
        print("  - Recherche dans les m√©moires avec scoring")
        print("  - R√©cup√©ration des d√©tails des conversations pertinentes")
        print("  - Ajout automatique des informations importantes")
        print("  - Sauvegarde compl√®te √† la fin")
    
    def _show_memories(self):
        """Afficher les m√©moires"""
        try:
            result = list_memories()
            data = json.loads(result)
            
            if data.get("status") == "success":
                memories = data.get("memories", [])
                print(f"\nüíæ M√âMOIRES ({len(memories)} trouv√©es):")
                for i, mem in enumerate(memories[:10], 1):
                    print(f"\n{i}. {mem.get('content', 'N/A')[:100]}...")
                    print(f"   Cat√©gorie: {mem.get('category', 'N/A')}")
                    print(f"   Date: {mem.get('timestamp', 'N/A')}")
            else:
                print(f"‚ö†Ô∏è Erreur: {data.get('message')}")
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
    
    def _interactive_search(self):
        """Recherche interactive avanc√©e"""
        query = input("üîç Terme de recherche: ").strip()
        if not query:
            return
        
        print(f"\nüîç Recherche intelligente de: '{query}'")
        
        # Rechercher dans les conversations
        conversations = self._search_relevant_conversations(query)
        if conversations:
            print(f"\nüìö CONVERSATIONS PERTINENTES ({len(conversations)}):")
            for i, conv in enumerate(conversations, 1):
                print(f"\n{i}. Score: {conv.get('score', 0):.3f}")
                print(f"   R√©sum√©: {conv.get('summary', 'N/A')[:200]}...")
                print(f"   Date: {conv.get('timestamp', 'N/A')}")
                
                # Proposer de voir les d√©tails
                if conv.get('score', 0) > 0.7:
                    choice = input(f"   Voir les d√©tails de la conversation {i}? (y/n): ").lower()
                    if choice == 'y':
                        full_transcript = self._get_full_conversation(conv.get('chat_id'))
                        if full_transcript:
                            print(f"\nüìñ D√âTAILS COMPLETS:\n{full_transcript[:500]}...")
        
        # Rechercher dans les m√©moires
        memories = self._search_memories(query)
        if memories:
            print(f"\nüíæ M√âMOIRES PERTINENTES ({len(memories)}):")
            for i, mem in enumerate(memories, 1):
                print(f"\n{i}. Score: {mem.get('similarity_score', 0):.3f}")
                print(f"   Contenu: {mem.get('content', 'N/A')[:200]}...")
                print(f"   Cat√©gorie: {mem.get('category', 'N/A')}")

def main():
    """Fonction principale"""
    print("üß† Chat Avanc√© avec Mistral - Version Compl√®te")
    print("=" * 60)
    
    # V√©rifier la configuration
    if not MISTRAL_ENABLED or not MISTRAL_API_KEY:
        print("‚ö†Ô∏è ATTENTION: Mistral n'est pas configur√©!")
        print("   Configurez MISTRAL_API_KEY dans votre fichier .env")
        print("   Le chat fonctionnera en mode limit√©")
        print()
    
    # Cr√©er et d√©marrer le chat
    chat = AdvancedChat()
    chat.chat_loop()

if __name__ == "__main__":
    main()
